{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing_tools.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammedovich/ML/blob/main/data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ikcDvz25dBB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvjFDXJ-56QT"
      },
      "source": [
        " dataset = pd.read_csv('Data.csv')\n",
        " # : - is a range between columns to select\n",
        " # automatically, take all columns except the last column\n",
        " # [:, :-1] - the first ':' is the lower band i.e. starting at 0, ':-1' is the\n",
        " # higher band except the last column\n",
        " x = dataset.iloc[:, :-1].values\n",
        "\n",
        "# [:, -1] note that we removed the range ':' from second param, as it will select\n",
        "# select the last column ONLY\n",
        " y = dataset.iloc[:, -1].values\n",
        " "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1gIT53L8gJ8",
        "outputId": "de3907b7-3b02-4164-9bb0-84fcf32a14a4"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgJhm_2M8iFD",
        "outputId": "5bdce5cc-5a06-40ab-bbfa-ebfa4d1820bd"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl92LzFqBaXd"
      },
      "source": [
        "# in  a situation where you have a large dataset, and you have 1% of missing data\n",
        "# you can just delete the data as it will have no impact on the model being trained\n",
        "# and no loss of accuracy.\n",
        "# to handle missing data, use sklearn - impute\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "# selecting numeric values to be replaced\n",
        "imputer.fit(x[:, 1:3])\n",
        "\n",
        "# transform and update the columns those data been updated\n",
        "x[:, 1:3] = imputer.transform(x[:, 1:3])\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CrC-0_kDh5F",
        "outputId": "9079694d-a7ba-46d0-a968-6ea6dffaaee3"
      },
      "source": [
        "# So the transform will updated the missing columns with the overall average of\n",
        "# of i.e. age and salary. \n",
        "print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32vMHt9XKhiY"
      },
      "source": [
        "# here we want to compute the dataset i.e. the country column has to be transformed\n",
        "# to numeric representation, i.e.\n",
        "# France = 1.0 0.0 0.0\n",
        "# Spain = 0.0 0.0 1.0\n",
        "# Germany = 0.0 1.0 0.0\n",
        "# We converting these to numeric to simplify the model learning\n",
        "#------------------------------\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "# we have to cast to an array (ndarray) \n",
        "x = np.array(ct.fit_transform(x))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7DImfGyKi9U",
        "outputId": "7c7e4eca-de67-49ca-9728-012d24e186fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 0.0 44.0 72000.0]\n",
            " [1.0 0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 1.0 38.0 61000.0]\n",
            " [1.0 0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [0.0 1.0 0.0 0.0 35.0 58000.0]\n",
            " [1.0 0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 0.0 48.0 79000.0]\n",
            " [1.0 0.0 1.0 0.0 50.0 83000.0]\n",
            " [0.0 1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EYjvWoNKmjU"
      },
      "source": [
        "# We are transforming the last column of Purchased, the type is boolean which \n",
        "# will be converted to 0 and 1.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1qgKgd4K_uU",
        "outputId": "234b6618-dd57-4f07-8355-17f71b6121b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSTilZ4oNntF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD-UPoW0OvES",
        "outputId": "5ef283f4-fd9d-408f-9825-d162a54f2c97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [0.0 1.0 0.0 0.0 44.0 72000.0]\n",
            " [1.0 0.0 0.0 1.0 38.0 61000.0]\n",
            " [1.0 0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 0.0 48.0 79000.0]\n",
            " [1.0 0.0 1.0 0.0 50.0 83000.0]\n",
            " [0.0 1.0 0.0 0.0 35.0 58000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3JLSGHnOvji",
        "outputId": "b94cc358-e493-42d7-fdd6-e5207c6c924d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxNE_LJNOvyu",
        "outputId": "0fd1375e-c16b-46ce-e7fe-a25f6ae3c163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yirlkZgMOwAi",
        "outputId": "44f96aa6-4f74-4608-c4e8-a0c3ce0442bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLCY-jcCLk2C"
      },
      "source": [
        "# Feature Scaling is always done after 'Splitting the dataset into two seperate sets' \n",
        "# [WHAT] Featrure scaling: consists of scaling all your variables or your features\n",
        "# actually to make sure they all take values in the same scale\n",
        "# [WHY]: Tht the test set is supposed to be a brand new set on which you are going to evaluate your machine learning mode.\n",
        "# What this means, is that the test set is something you're not supposed to work with for the training and features.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}